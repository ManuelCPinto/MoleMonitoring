{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch.optim as optim\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\nimport seaborn as sns\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.preprocessing import label_binarize\nimport torch.nn.functional as F\n\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.metrics import accuracy_score\nimport timm\n\n# ---------------------------\n# Hyperparameters\n# ---------------------------\nNUM_EPOCHS = 150\nBATCH_SIZE = 32\nLEARNING_RATE = 1e-4\nDROPOUT_P = 0.3\nPATIENCE = 25\nTARGET_SAMPLES_PER_CLASS = 2000 \n\n# ---------------------------\n# Define Paths\n# ---------------------------\nBASE_PATH = \"/kaggle/input/ham10000\"\n    \n# HAM10000 paths\nHAM_IMAGES_FOLDER = os.path.join(BASE_PATH, \"HAM10000\", \"HAM10000_images\")\nHAM_METADATA_FILE = os.path.join(BASE_PATH, \"HAM10000\", \"HAM10000_metadata\")  # Ensure CSV\n\n# ISIC2018 paths\nISIC_IMAGES_FOLDER = os.path.join(BASE_PATH, \"ISIC2018_images\", \"ISIC2018_images\")\nISIC_METADATA_FILE = os.path.join(BASE_PATH, \"ISIC2018_images\", \"ISIC2018_metadata\")  # Ensure CSV\n\nCHECKPOINT_PATH = \"best_fusion_model.pth\"\n\n# ---------------------------\n# Augmentation Strategy\n# ---------------------------\ntrain_transform = A.Compose([\n    A.HorizontalFlip(),\n    A.VerticalFlip(),\n    A.RandomRotate90(),\n    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=180, p=0.5),\n    A.RandomBrightnessContrast(p=0.2),\n    A.HueSaturationValue(p=0.2),\n    A.Resize(224, 224),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\n\ntest_transform = A.Compose([\n    A.Resize(224, 224),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\n\n# -----------\n# Model\n# -----------\n\nclass FusionModelTimm(nn.Module):\n    def __init__(self, num_classes=7):\n        super(FusionModelTimm, self).__init__()\n        # ---------------------------\n        # EfficientNet-b3 Branch (via timm)\n        # ---------------------------\n        self.efficientnet = timm.create_model('efficientnet_b3', pretrained=True, num_classes=0)\n        # Expected feature dimension: 1536\n        \n        # ---------------------------\n        # ResNet50 Branch (via timm)\n        # ---------------------------\n        self.resnet50 = timm.create_model('resnet50', pretrained=True, num_classes=0)\n        # Expected feature dimension: 2048\n        \n        # ---------------------------\n        # ViT Branch (via timm)\n        # ---------------------------\n        # Using ViT-Base with patch size 16 (feature dimension typically 768)\n        self.vit = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=0)\n        \n        # ---------------------------\n        # Fusion Classifier\n        # ---------------------------\n        # Total concatenated features: 1536 + 2048 + 768 = 4352\n        fusion_in_features = 4352\n        self.classifier = nn.Sequential(\n            nn.Linear(fusion_in_features, 512),\n            nn.ReLU(),\n            nn.Dropout(DROPOUT_P),\n            nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, x):\n        # Get features from each branch\n        x_e = self.efficientnet(x)  # Shape: [B, 1536]\n        x_r = self.resnet50(x)      # Shape: [B, 2048]\n        x_v = self.vit(x)           # Shape: [B, 768]\n        \n        # Concatenate features from all three branches\n        x_fused = torch.cat((x_e, x_r, x_v), dim=1)  # Shape: [B, 4352]\n        \n        # Classify fused features\n        logits = self.classifier(x_fused)\n        return logits\n\n# ---------------------------\n# Custom Dataset with Oversampling & Augmentation\n# ---------------------------\nclass SkinLesionDataset(Dataset):\n    def __init__(self, metadata, images_folder, label_map, transform=None, oversample=True):\n        self.metadata = metadata\n        self.images_folder = images_folder\n        self.label_map = label_map\n        self.transform = transform\n\n        self.augmented_data = []\n        class_counts = self.metadata[\"dx\"].value_counts().to_dict()\n\n        for cls, count in class_counts.items():\n            class_data = self.metadata[self.metadata[\"dx\"] == cls]\n            multiplier = 1\n            if oversample:\n                multiplier = max(1, min(TARGET_SAMPLES_PER_CLASS // count, 10))\n            self.augmented_data.extend([row for _, row in class_data.iterrows()] * multiplier)\n        \n        self.augmented_data = pd.DataFrame(self.augmented_data).reset_index(drop=True)\n\n    def __len__(self):\n        return len(self.augmented_data)\n\n    def __getitem__(self, idx):\n        row = self.augmented_data.iloc[idx]\n        img_id = row[\"image_id\"]\n        dx = row[\"dx\"]\n        label = self.label_map[dx]\n\n        img_path = os.path.join(self.images_folder, f\"{img_id}.jpg\")\n        image = Image.open(img_path).convert(\"RGB\")\n        image = np.array(image)\n\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented[\"image\"]\n\n        return image.float(), torch.tensor(label, dtype=torch.long)\n    \n# ---------------------------\n# Evaluation Function\n# ---------------------------\ndef evaluate_dataset(model, loader, device, ham_classes, num_classes, title=\"Test Data\"):\n    y_true, y_pred, y_prob = [], [], []\n    model.eval()\n    with torch.no_grad():\n        for images, labels in loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            probs = F.softmax(outputs, dim=1)\n            preds = outputs.argmax(dim=1)\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n            y_prob.extend(probs.cpu().numpy())\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    y_prob = np.array(y_prob)\n\n    print(f\"\\n**Classification Report on {title}:**\")\n    print(classification_report(y_true, y_pred, target_names=ham_classes))\n    cm = confusion_matrix(y_true, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=ham_classes, yticklabels=ham_classes)\n    plt.title(f\"Confusion Matrix - {title}\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.show()\n\n    y_true_bin = label_binarize(y_true, classes=list(range(num_classes)))\n    for i in range(num_classes):\n        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_prob[:, i])\n        roc_auc = auc(fpr, tpr)\n        plt.plot(fpr, tpr, label=f\"{ham_classes[i]} (AUC = {roc_auc:.2f})\")\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0, 1])\n    plt.ylim([0, 1])\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(f\"ROC Curves - {title}\")\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n# ---------------------------\n# Load & Prepare Datasets\n# ---------------------------\nham_metadata = pd.read_csv(HAM_METADATA_FILE)\nham_classes = sorted(ham_metadata[\"dx\"].unique())\nlabel_map = {name: idx for idx, name in enumerate(ham_classes)}\nNUM_CLASSES = len(label_map)\n\ntrain_df, temp_df = train_test_split(ham_metadata, test_size=0.2, stratify=ham_metadata[\"dx\"], random_state=42)\nval_df, ham_test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"dx\"], random_state=42)\nprint(f\"HAM Training samples: {len(train_df)}, Validation samples: {len(val_df)}, Test samples: {len(ham_test_df)}\")\n\nclass_counts = train_df[\"dx\"].value_counts().to_dict()\ntotal_samples = sum(class_counts.values())\nclass_weights = {label_map[cls]: total_samples / (len(class_counts) * count) for cls, count in class_counts.items()}\nclass_weights_tensor = torch.tensor(list(class_weights.values()), dtype=torch.float).to(\"cuda\")\n\ntrain_dataset = SkinLesionDataset(train_df, HAM_IMAGES_FOLDER, label_map, transform=train_transform)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n\nval_dataset = SkinLesionDataset(val_df, HAM_IMAGES_FOLDER, label_map, transform=test_transform, oversample=False)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\nham_test_dataset = SkinLesionDataset(ham_test_df, HAM_IMAGES_FOLDER, label_map, transform=test_transform, oversample=False)\nham_test_loader = DataLoader(ham_test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\nisic_metadata = pd.read_csv(ISIC_METADATA_FILE)\nisic_test_dataset = SkinLesionDataset(isic_metadata, ISIC_IMAGES_FOLDER, label_map, transform=test_transform, oversample=False)\nisic_test_loader = DataLoader(isic_test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\n# ---------------------------\n# Model, Loss, and Optimizer Setup\n# ---------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = FusionModelTimm(num_classes=NUM_CLASSES)\nmodel.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\ndef evaluate(loader, model):\n    model.eval()\n    total_loss, correct, total = 0.0, 0, 0\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n    avg_loss = total_loss / len(loader)\n    accuracy = correct / total\n    return avg_loss, accuracy\n\nbest_val_acc = 0.0\npatience_counter = 0\n\n# -----------\n# Train Loop\n# -----------\nfor epoch in range(NUM_EPOCHS):\n     model.train()\n     running_loss, correct_train, total_train = 0.0, 0, 0\n     for images, labels in train_loader:\n         images, labels = images.to(device), labels.to(device)\n         optimizer.zero_grad()\n         outputs = model(images)\n         loss = criterion(outputs, labels)\n         loss.backward()\n         optimizer.step()\n\n         running_loss += loss.item()\n         _, predicted = torch.max(outputs, 1)\n         correct_train += (predicted == labels).sum().item()\n         total_train += labels.size(0)\n\n     avg_train_loss = running_loss / len(train_loader)\n     train_acc = correct_train / total_train\n\n     val_loss, val_acc = evaluate(val_loader, model)\n     print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}] -> Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\n     if val_acc > best_val_acc:\n         best_val_acc = val_acc\n         patience_counter = 0\n         torch.save(model.state_dict(), CHECKPOINT_PATH)\n         print(\"New best model!\")\n     else:\n         patience_counter += 1\n         if patience_counter >= PATIENCE:\n             print(\"Early stopping triggered!\")\n             break\n\n# Load the best fusion model\nmodel.load_state_dict(torch.load(CHECKPOINT_PATH, map_location=device))\nmodel.eval()\n\n# ---------------------------\n# Evaluation on HAM Test Set\n# ---------------------------\nevaluate_dataset(model, ham_test_loader, device, ham_classes, NUM_CLASSES, title=\"HAM Test Set\")\n\n# ---------------------------\n# Evaluation on ISIC Test Set\n# ---------------------------\nevaluate_dataset(model, isic_test_loader, device, ham_classes, NUM_CLASSES, title=\"ISIC Test Set\")\n\n# ---------------------------\n# Feature Extractor for SVM (using the fusion model's branches)\n# ---------------------------\nclass FusionFeatureExtractor(nn.Module):\n    def __init__(self, fusion_model):\n        super(FusionFeatureExtractor, self).__init__()\n        self.efficientnet = fusion_model.efficientnet  # 1536-dim\n        self.resnet50 = fusion_model.resnet50          # 2048-dim\n        self.vit = fusion_model.vit                    # 768-dim\n        \n    def forward(self, x):\n        x_e = self.efficientnet(x)\n        x_r = self.resnet50(x)\n        x_v = self.vit(x)\n        x_fused = torch.cat((x_e, x_r, x_v), dim=1)  # Shape: [B, 4352]\n        return x_fused\n\nfeature_extractor = FusionFeatureExtractor(model)\nfeature_extractor.to(device)\nfeature_extractor.eval()\n\ndef extract_features(loader, model, device):\n    features, labels = [], []\n    model.eval()\n    with torch.no_grad():\n        for images, targets in loader:\n            images = images.to(device)\n            targets = targets.cpu().numpy()\n            \n            feats = model(images)  # Extract features\n            feats = feats.cpu().numpy()  # Move to CPU for sklearn\n            \n            features.append(feats)\n            labels.append(targets)\n\n    return np.vstack(features), np.hstack(labels)\n\n# Extract features from datasets for SVM training/evaluation\nX_train, y_train = extract_features(train_loader, feature_extractor, device)\nX_val, y_val = extract_features(val_loader, feature_extractor, device)\nX_test, y_test = extract_features(ham_test_loader, feature_extractor, device)\nX_test_I, y_test_I = extract_features(isic_test_loader, feature_extractor, device)\n\nprint(\"Training SVM classifier...\")\n# Train an SVM classifier on the extracted features\nsvm_model = make_pipeline(StandardScaler(), SVC(kernel=\"sigmoid\", probability=True))\nsvm_model.fit(X_train, y_train)\n\ndef evaluate_svm_model(model, X_test, y_test, class_names):\n    y_pred = model.predict(X_test)\n    y_prob = model.predict_proba(X_test)\n    \n    print(\"\\n**Classification Report:**\")\n    print(classification_report(y_test, y_pred, target_names=class_names))\n    \n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.show()\n    \n    # One-hot encoding of y_test for multi-class ROC curve\n    y_test_bin = label_binarize(y_test, classes=np.arange(len(class_names)))\n    \n    plt.figure(figsize=(10, 8))\n    for i in range(len(class_names)):\n        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n        roc_auc = auc(fpr, tpr)\n        plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc:.2f})\")\n    \n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0, 1])\n    plt.ylim([0, 1])\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.title(\"ROC Curves & AUC Scores\")\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n# Run SVM evaluation\nprint(\"Evaluating SVM on HAM test set:\")\nevaluate_svm_model(svm_model, X_test, y_test, ham_classes)\n\nprint(\"Evaluating SVM on ISIC test set:\")\nevaluate_svm_model(svm_model, X_test_I, y_test_I, ham_classes)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}